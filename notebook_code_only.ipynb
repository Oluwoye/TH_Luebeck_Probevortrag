{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Einführung in das Machine Learning (Woche 3): Von Daten zu Vorhersagen\n",
    "\n",
    "In dieser Vorlesung werden Sie lernen, wie Sie von einem Beispieldatensatz im csv-Format zu einem ersten Machine-Learning Modell gelangen.\n",
    "\n",
    "## Jupyter und Jupyter Notebooks\n",
    "\n",
    "Jupyter ist ein Framework zum interaktiven Programmieren. Letzte Woche haben Sie bereits im Tutorium Python und Pip aufgesetzt. Deshalb ist es nun ganz einfach, dass Sie auch Jupyter aufsetzen, installieren Sie es einfach via:\n",
    "\n",
    "``` pip install jupyter ```\n",
    "\n",
    "In Pycharm können Sie ein Notebook lokal starten (dies habe ich getan; [offizielle Hilfeseite für Pycharm](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html)), ansonsten führen Sie einfach:\n",
    "\n",
    "``` jupyter lab ```\n",
    "\n",
    "um es im Browser zu starten. Bei Problemen konsultieren Sie bitte zuerst die Dokumentation von Jupyter ([Dokumentation](https://docs.jupyter.org/en/latest/)) und fragen, wenn die Probleme weiter bestehen, im Tutorium.\n",
    "\n",
    "Der Vorteil von Jupyter Notebooks gegenüber reinem Scripting in nativem Python ist, dass Sie Zwischenergebnisse sich anzeigen lassen können und interaktiv schnell Feedback auf kleine Code-Snippets bekommen können. Wir verwenden es hier in der Vorlesung für Lernzwecke. Ich möchte darauf hinweisen, dass Sie Jupyter auch in der Industrie zum schnellen Testen von Ideen nutzen können oder um Kunden etwas zu präsentieren (Stichwort: Fast Prototyping), allerdings ist es zum Produktivbetrieb regelmäßig ungeeignet, da die interaktive Engine (der Jupyter-Server) im Hintergrund die Ausführung Ihres Programmes verlangsamt."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Hello World!\")\n",
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%pip install pandas\n",
    "import pandas\n",
    "from pandas import DataFrame # Das DataFrame (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) ist die zentrale In-Memory Struktur in Pandas. Sie können es sich wie eine kleine Excel-Tabelle oder eine relationale Datenbank in Ihrem Hauptspeicher vorstellen."
   ],
   "id": "6d7bad4b1d5b128e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "df = pandas.read_csv(os.path.join(\"titanic_data\", \"train.csv\"))\n",
    "\n",
    "# Ignorieren Sie für den Moment die test.csv und test_transformed.csv. Wir gehen später darauf ein, warum es sinnvoll ist, zwischen Trainings- und Testdatensatz zu unterscheiden.\n",
    "\n",
    "df.head(10)"
   ],
   "id": "6d7fc0627335232a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "target = df[\"Survived\"]\n",
    "df = df.drop(columns=[\"Survived\"])\n",
    "df.head(10)"
   ],
   "id": "3c12abb23291fbdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "target",
   "id": "89ca40ca60d5d74a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\"])\n",
    "\n",
    "sex_one_hot = pandas.get_dummies(df[\"Sex\"], dtype=\"int\")\n",
    "embarked_one_hot = pandas.get_dummies(df[\"Embarked\"], dtype=\"int\")\n",
    "\n",
    "sex_one_hot"
   ],
   "id": "b9fc421d8bdb4aae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "embarked_one_hot",
   "id": "43c82b4781fea09d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df.drop(columns = [\"Sex\", \"Embarked\"]) # Es gibt kein Grund die gleiche Information zweimal im Datensatz codiert zu halten\n",
    "df = df.join(sex_one_hot)\n",
    "df = df.join(embarked_one_hot)\n",
    "\n",
    "df.head(10)"
   ],
   "id": "4f5aed40154910e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.drop(columns = [\"male\", \"S\"])",
   "id": "ad73d8ad14aac8af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fares = df[\"Fare\"]\n",
    "passenger_classes = df[\"Pclass\"]\n",
    "\n",
    "passenger_class_1_indices = df.index[df['Pclass'] == 1]\n",
    "passenger_class_2_indices = df.index[df['Pclass'] == 2]\n",
    "passenger_class_3_indices = df.index[df['Pclass'] == 3]\n",
    "\n",
    "fares_class_1 = fares[passenger_class_1_indices]\n",
    "fares_class_2 = fares[passenger_class_2_indices]\n",
    "fares_class_3 = fares[passenger_class_3_indices]\n",
    "\n",
    "print(f\"Tickets for class 1 were sold at max for: {fares_class_1.max()} and at min for {fares_class_1.min()}\")\n",
    "print(f\"Tickets for class 2 were sold at max for: {fares_class_2.max()} and at min for {fares_class_2.min()}\")\n",
    "print(f\"Tickets for class 3 were sold at max for: {fares_class_3.max()} and at min for {fares_class_3.min()}\")"
   ],
   "id": "c3e5d3cb4e6c66f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(10)",
   "id": "f46d89a3f7bdf4c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cabin = df[\"Cabin\"]\n",
    "age = df[\"Age\"]\n",
    "\n",
    "print(f\"NaN share in Cabin: {cabin.isna().sum()/len(cabin)*100:.2f} %\")\n",
    "print(f\"NaN share in Age: {age.isna().sum()/len(cabin)*100:.2f} %\")"
   ],
   "id": "b9fd20c0e766312a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%pip install numpy\n",
    "import numpy"
   ],
   "id": "bf8f1e26f561a469",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df.drop(columns=[\"Cabin\"])\n",
    "age = age.to_numpy() # Übergang von Pandas zu Numpy über explizites Interface"
   ],
   "id": "fc2e2670a6fdb644",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "age",
   "id": "6792d1231b10d2d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"The minimum age is: {numpy.nanmin(age)}\") # Nanmin ignoriert alle NaN Werte. Einfach nur \"min\" zu rufen, würde hingegen in der Rückgabe NaN resultieren.\n",
    "print(f\"For reference: {numpy.min(age)}\") # Das Gleiche gilt für die weiteren Funktionen.\n",
    "print(f\"The maximum age is: {numpy.nanmax(age)}\")\n",
    "print(f\"The mean value is: {numpy.nanmean(age)}\") # Der Mean muss kein Element der Daten selber sein!\n",
    "print(f\"The median age is: {numpy.nanmedian(age)}\")\n",
    "vals,counts = numpy.unique(age[~numpy.isnan(age)], return_counts=True) # ~numpy.isnan(age) exkludiert für einen Moment alle NaN-Werte. ~ ist die Negation.\n",
    "print(f\"The mode age is: {vals[numpy.argmax(counts)]}\") # Der Mode lässt sich leider noch immer nicht komfortabel in einem Schritt berechnen\n",
    "print(f\"For reference: All age values \\n {vals} \\n with their respective counts \\n {counts}\")"
   ],
   "id": "a83a88033317b849",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(age, bins=len(counts))\n",
    "print(f\"The standard deviation is: {numpy.nanstd(age)}\")"
   ],
   "id": "924e29c8e2bac0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "age = numpy.nan_to_num(age, copy=True, nan=numpy.nanmedian(age))\n",
    "df[\"Age\"] = age # Übergang von Numpy zu Pandas über implizites Interface. Gefahr!\n",
    "df.head(10)"
   ],
   "id": "38560a1fa0e1af61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%pip install scikit-learn\n",
    "import sklearn"
   ],
   "id": "59d5de2fdf8afaef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn import tree\n",
    "\n",
    "data = df.to_numpy()\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5) # Maximal 5 Wenn-Dann-Fragen\n",
    "clf.fit(data, target)"
   ],
   "id": "397aedd79fa3cff3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "print(\"Visualization of the Decision Tree:\")\n",
    "pyplot.figure(figsize=(12, 12))\n",
    "tree.plot_tree(clf, feature_names=df.columns, max_depth=2)\n",
    "pyplot.show()"
   ],
   "id": "1132f987eaf51e31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "r = tree.export_text(clf, feature_names=df.columns)\n",
    "print(\"Verbal Description of Decision Tree\")\n",
    "print(r)"
   ],
   "id": "e1b4b8fa8117436a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_test = pandas.read_csv(os.path.join(\"titanic_data\", \"test.csv\"))\n",
    "df_test_transformed = pandas.read_csv(os.path.join(\"titanic_data\", \"test_transformed.csv\"))\n",
    "\n",
    "df_test_transformed.head(10)"
   ],
   "id": "611fc389d4a8e4c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ground_truth = df_test[\"Survived\"].to_numpy()\n",
    "data_test = df_test_transformed.to_numpy()\n",
    "predicted_truth = clf.predict(data_test)"
   ],
   "id": "b02553112910fe73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ground_truth",
   "id": "3140c01453fad091",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predicted_truth",
   "id": "5c62b10222e834bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(sklearn.metrics.classification_report(ground_truth, predicted_truth))",
   "id": "78d7cdf8553f1d3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Abschluss\n",
    "\n",
    "Herzlichen Glückwunsch! Sie haben erfolgreich Ihre erste Machine-Learning-Pipeline durchgestanden und ein 77% der ungesehenen Beispiele richtig erraten.\n",
    "\n",
    "Damit schließen wir die heutige Vorlesung. Für weitere Fragen kontaktieren Sie mich gerne unter tim.barz-cech@th-luebeck.de. Ansonsten freue ich mich wie immer über ihr Feedback und wir sehen uns beim nächsten Termin! Wie bereits geübt gilt: Sie haben diese Vorlesung aller Wahrscheinlichkeit nach verstanden, wenn Sie alle Fragen selbstständig ohne Hilfsmittel beantworten können. Bitte wiederholen Sie die Vorlesung frühzeitig, damit Sie nicht zur Prüfungszeit in zu großen Stress geraten.\n",
    "\n",
    "Solange haben Sie eine schöne Zeit!"
   ],
   "id": "fe2fe09503badf91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
